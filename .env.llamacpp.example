# =============================================================================
# LlamaCpp + OpenLPR Environment Configuration
# =============================================================================

# =============================================================================
# HuggingFace Configuration
# =============================================================================
# Your HuggingFace access token (required for some models)
# Get it from: https://huggingface.co/settings/tokens
HF_TOKEN=your token goes here

# Model repository and file configuration
MODEL_REPO=unsloth/Qwen3-VL-4B-Instruct-GGUF
MODEL_FILE=Qwen3-VL-4B-Instruct-Q5_K_M.gguf
LLAMA_ARG_MMPROJ_URL=https://huggingface.co/unsloth/Qwen3-VL-4B-Instruct-GGUF/resolve/main/mmproj-BF16.gguf

# =============================================================================
# Django Settings
# =============================================================================
SECRET_KEY=django-insecure-change-me-in-production-use-a-strong-random-key
DEBUG=False
ALLOWED_HOSTS=localhost,127.0.0.1,0.0.0.0,lpr.localhost,lpr-app
# CSRF_TRUSTED_ORIGINS=https://your-domain.com

# =============================================================================
# File Upload Settings
# =============================================================================
UPLOAD_FILE_MAX_SIZE=256000  # 250KB in bytes
MAX_BATCH_SIZE=10

# =============================================================================
# Database Configuration
# =============================================================================
DATABASE_PATH=/app/data/db.sqlite3

# =============================================================================
# Monitoring Configuration
# =============================================================================
# Grafana Configuration
GRAFANA_USER=admin
GRAFANA_PASSWORD=admin

# Traefik Configuration (optional - for production)
# TRAEFIK_DOMAIN=your-domain.com
# TRAEFIK_EMAIL=admin@your-domain.com

# =============================================================================
# Qwen3-VL API Configuration
# =============================================================================
# API configuration for connecting to the LlamaCpp inference service
QWEN_API_KEY=sk-llamacpp-local
#when using a remote Open API comptaible endpoint
# QWEN_BASE_URL=https://your-api-endpoint.io/v1
#When running the bundled llamacpp using CPU (default)
QWEN_BASE_URL=http://llamacpp-cpu:8000/v1
#When running the bundled llamacpp using AMD GPUs
# QWEN_BASE_URL=http://llamacpp-amd-vulkan:8000/v1
#When running the bundled llamacpp using Nvidia GPUs
# QWEN_BASE_URL=http://llamacpp-nvidia-cuda:8000/v1
QWEN_MODEL=Qwen3-VL-4B-Instruct

# =============================================================================
# Optional: Superuser Creation
# =============================================================================
# Uncomment and set these values to automatically create a Django superuser
# DJANGO_SUPERUSER_USERNAME=admin
# DJANGO_SUPERUSER_EMAIL=admin@example.com
# DJANGO_SUPERUSER_PASSWORD=your-secure-password


# =============================================================================
# Production Settings (Uncomment for Production)
# =============================================================================
# ALLOWED_HOSTS=your-domain.com,www.your-domain.com
# DEBUG=False
# SECRET_KEY=generate-a-very-strong-random-key-here
# DJANGO_SUPERUSER_USERNAME=admin
# DJANGO_SUPERUSER_EMAIL=admin@your-domain.com
# DJANGO_SUPERUSER_PASSWORD=use-a-very-strong-password
